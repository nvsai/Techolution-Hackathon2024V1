{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZya_TBbtlov"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import zipfile\n",
        "\n",
        "\n",
        "\n",
        "# Unzip the file.\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/Copy of door_open_door_close_door_stop_max_1sec.zip\")\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4yHFLXy0FkZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pathlib\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQs7XCduz4Mr",
        "outputId": "a3769694-ed05-4da8-87a8-88abaa96420a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Commands Available: ['door_open' 'door_close' 'door_stop']\n"
          ]
        }
      ],
      "source": [
        "DATASET_PATH = '/tmp/hackathon'\n",
        "\n",
        "data_dir = pathlib.Path(DATASET_PATH)\n",
        "commands = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
        "commands = commands[(commands != 'README.md') & (commands != '.DS_Store')]\n",
        "print('Commands Available:', commands)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRyxQCPh1Sb2",
        "outputId": "466c2103-d8a8-43bc-9728-31e6bbf1ff31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12674 files belonging to 3 classes.\n",
            "Using 10140 files for training.\n",
            "Using 2534 files for validation.\n",
            "\n",
            "label : ['door_close' 'door_open' 'door_stop']\n"
          ]
        }
      ],
      "source": [
        "train_ds, val_ds = tf.keras.utils.audio_dataset_from_directory(\n",
        "    directory=data_dir,\n",
        "    batch_size=64,\n",
        "    validation_split=0.2,\n",
        "    seed=0,\n",
        "    output_sequence_length=16000,\n",
        "    subset='both')\n",
        "\n",
        "label_names = np.array(train_ds.class_names)\n",
        "print()\n",
        "print(\"label :\", label_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZ5CWMex1H6G"
      },
      "outputs": [],
      "source": [
        "def squeeze(audio, labels):\n",
        "  audio = tf.squeeze(audio, axis=-1)\n",
        "  return audio, labels\n",
        "\n",
        "train_ds = train_ds.map(squeeze, tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.map(squeeze, tf.data.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMcpBE851f8g"
      },
      "outputs": [],
      "source": [
        "test_ds = val_ds.shard(num_shards=2, index=0)\n",
        "val_ds = val_ds.shard(num_shards=2, index=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5uCiZDD1pXY"
      },
      "outputs": [],
      "source": [
        "def get_spectrogram(waveform):\n",
        "  # Convert the waveform to a spectrogram via a STFT.\n",
        "  spectrogram = tf.signal.stft(\n",
        "      waveform, frame_length=255, frame_step=128)\n",
        "  # Obtain the magnitude of the STFT.\n",
        "  spectrogram = tf.abs(spectrogram)\n",
        "  # Add a `channels` dimension so that the Spectrogram can be used\n",
        "  spectrogram = spectrogram[..., tf.newaxis]\n",
        "  return spectrogram\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSKEWBVM1r9m"
      },
      "outputs": [],
      "source": [
        "def make_spec_ds(ds):\n",
        "  return ds.map(\n",
        "      map_func=lambda audio,label: (get_spectrogram(audio), label),\n",
        "      num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "train_spectrogram_ds = make_spec_ds(train_ds)\n",
        "val_spectrogram_ds = make_spec_ds(val_ds)\n",
        "test_spectrogram_ds = make_spec_ds(test_ds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4h-PiPaT2Be2",
        "outputId": "f50865e7-7f90-4ced-924d-a421c2347b0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_8 (Conv2D)           (None, 122, 127, 16)      160       \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 120, 125, 16)      2320      \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 240000)            0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               30720128  \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30722737 (117.20 MB)\n",
            "Trainable params: 30722737 (117.20 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(16, (3,3), activation='relu', input_shape=(124, 129, 1)))\n",
        "model.add(layers.Conv2D(16, (3,3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='softmax'))\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWbYQvWQ2GYQ",
        "outputId": "9811f57c-2fb2-41a3-e5ba-ae4bc501e918"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "159/159 [==============================] - 330s 2s/step - loss: -46186.6172 - recall_4: 1.0000 - precision_4: 0.7249 - val_loss: -311943.5000 - val_recall_4: 1.0000 - val_precision_4: 0.7242\n",
            "Epoch 2/10\n",
            "159/159 [==============================] - 333s 2s/step - loss: -3016546.7500 - recall_4: 1.0000 - precision_4: 0.7249 - val_loss: -9233793.0000 - val_recall_4: 1.0000 - val_precision_4: 0.7242\n",
            "Epoch 3/10\n",
            "159/159 [==============================] - 323s 2s/step - loss: -27248052.0000 - recall_4: 1.0000 - precision_4: 0.7249 - val_loss: -59191968.0000 - val_recall_4: 1.0000 - val_precision_4: 0.7242\n",
            "Epoch 4/10\n",
            "159/159 [==============================] - 329s 2s/step - loss: -115191208.0000 - recall_4: 1.0000 - precision_4: 0.7249 - val_loss: -201839664.0000 - val_recall_4: 1.0000 - val_precision_4: 0.7242\n",
            "Epoch 5/10\n",
            "159/159 [==============================] - 317s 2s/step - loss: -319505792.0000 - recall_4: 1.0000 - precision_4: 0.7249 - val_loss: -498809184.0000 - val_recall_4: 1.0000 - val_precision_4: 0.7242\n",
            "Epoch 6/10\n",
            "159/159 [==============================] - 329s 2s/step - loss: -702312320.0000 - recall_4: 1.0000 - precision_4: 0.7249 - val_loss: -1018759488.0000 - val_recall_4: 1.0000 - val_precision_4: 0.7242\n",
            "Epoch 7/10\n",
            "159/159 [==============================] - 312s 2s/step - loss: -1333849216.0000 - recall_4: 1.0000 - precision_4: 0.7249 - val_loss: -1816151808.0000 - val_recall_4: 1.0000 - val_precision_4: 0.7242\n",
            "Epoch 8/10\n",
            "159/159 [==============================] - 313s 2s/step - loss: -2278283008.0000 - recall_4: 1.0000 - precision_4: 0.7249 - val_loss: -2990779392.0000 - val_recall_4: 1.0000 - val_precision_4: 0.7242\n",
            "Epoch 9/10\n",
            "159/159 [==============================] - 318s 2s/step - loss: -3610601216.0000 - recall_4: 1.0000 - precision_4: 0.7249 - val_loss: -4596045824.0000 - val_recall_4: 1.0000 - val_precision_4: 0.7242\n",
            "Epoch 10/10\n",
            "159/159 [==============================] - 353s 2s/step - loss: -5405113344.0000 - recall_4: 1.0000 - precision_4: 0.7249 - val_loss: -6736413184.0000 - val_recall_4: 1.0000 - val_precision_4: 0.7242\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x790a9201a620>"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Compiling and fitting the model\n",
        "model.compile('Adam', loss='BinaryCrossentropy', metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])\n",
        "\n",
        "model.fit(train_spectrogram_ds, epochs=10, validation_data=test_spectrogram_ds)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "23nCO8WL6AYt"
      },
      "outputs": [],
      "source": [
        "# Prediction for a data\n",
        "\n",
        "audio, labels = train_ds.take(2)\n",
        "\n",
        "yhat = model.predict(audio)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bdkYPQVf2hZt"
      },
      "outputs": [],
      "source": [
        "for i in zip(audio,y_hat):\n",
        "    print(i[0].shape)\n",
        "    plt.figure(figsize=(30,20))\n",
        "    plt.text(0, 0, \"Predicted Class = \"+str(i[1])[0],fontsize = 33,\n",
        "         bbox = dict(facecolor = 'red', alpha = 0.2))\n",
        "    plt.imshow(np.transpose(i[0])[0])\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhWn4aDK2JLW",
        "outputId": "35b8ebb4-56e6-4405-92af-873e2976709a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save('my_model_CNN-1937.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjXjqenpGJg6"
      },
      "source": [
        "Using librose ms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H241T3UbGPdT"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9VmlG8WMaj1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "directory_path = \"/tmp/hackathon/\"  # Replace with the actual path\n",
        "\n",
        "# Option 1: Using os.listdir()\n",
        "folders = os.listdir(directory_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pad2d = lambda a, i: a[:, 0: i] if a.shape[1] > i else np.hstack((a, np.zeros((a.shape[0],i - a.shape[1]))))"
      ],
      "metadata": {
        "id": "QYCCLY3sV6lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DfGJrJ7ML3dP"
      },
      "outputs": [],
      "source": [
        "def process_audio_file(label,filename):\n",
        "    # Load audio\n",
        "    audio, sr = librosa.load(directory_path+label+\"/\"+filename)\n",
        "    print(sr)\n",
        "    print(audio.shape)\n",
        "    # Preprocess audio (optional)\n",
        "    audio = librosa.util.normalize(audio)  # Normalize volume\n",
        "\n",
        "    # Extract features\n",
        "    spectrogram = librosa.stft(audio)\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sr)  # Example feature extraction\n",
        "\n",
        "    return  mfccs, filename  # Return multiple features and filename"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocEAYpMYL6Zo"
      },
      "outputs": [],
      "source": [
        "audio_data = []\n",
        "labels = []\n",
        "for labelname in folders:\n",
        "  files=os.listdir(directory_path+labelname+\"/\")\n",
        "  for filename in files:\n",
        "      mfccs, label = process_audio_file(labelname,filename)\n",
        "      padded_mfcc = pad2d(mfccs,40)\n",
        "      audio_data.append(padded_mfcc)\n",
        "      z=0\n",
        "      if labelname=='door_close':\n",
        "        z=1\n",
        "      if labelname=='door_stop':\n",
        "        z=2\n",
        "      labels.append(z)  # Assuming labels are extracted from filenames\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_data=np.array(audio_data)\n",
        "labels=to_categorical(np.array(labels))"
      ],
      "metadata": {
        "id": "9lZ3mHFST0Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = np.expand_dims(audio_data, -1)"
      ],
      "metadata": {
        "id": "okwQdfJrWpJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7kGW_cJL7Vj"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(audio_data, labels, test_size=0.2)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlKKNTfJXw9B"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import LSTM, Dense, Input\n",
        "from tensorflow.keras.models import Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpMPBxFa29OR"
      },
      "outputs": [],
      "source": [
        "\n",
        "inputs = Input(shape=(X_train[0].shape))\n",
        "\n",
        "# Recurrent layers for sequence processing\n",
        "x = LSTM(64, return_sequences=True)(inputs)  # First LSTM layer\n",
        "x = LSTM(32)(x)  # Second LSTM layer\n",
        "x = LSTM(64, return_sequences=True, dropout=0.2)(inputs)  # Dropout rate of 20%\n",
        "x = LSTM(32, dropout=0.2)(x)\n",
        "# Output layer for categorical classification\n",
        "outputs = Dense(3, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vOs3pq3C3fUj"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKi4ditY4hpM",
        "outputId": "5a91081a-a9c3-4e76-b23b-38b138e05614"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "254/254 [==============================] - 7s 26ms/step - loss: 0.1883 - accuracy: 0.9308 - val_loss: 0.1992 - val_accuracy: 0.9290\n",
            "Epoch 2/30\n",
            "254/254 [==============================] - 9s 35ms/step - loss: 0.1944 - accuracy: 0.9295 - val_loss: 0.1948 - val_accuracy: 0.9246\n",
            "Epoch 3/30\n",
            "254/254 [==============================] - 6s 26ms/step - loss: 0.1978 - accuracy: 0.9282 - val_loss: 0.2051 - val_accuracy: 0.9246\n",
            "Epoch 4/30\n",
            "254/254 [==============================] - 9s 36ms/step - loss: 0.1853 - accuracy: 0.9351 - val_loss: 0.1888 - val_accuracy: 0.9290\n",
            "Epoch 5/30\n",
            "254/254 [==============================] - 6s 25ms/step - loss: 0.1662 - accuracy: 0.9406 - val_loss: 0.1728 - val_accuracy: 0.9423\n",
            "Epoch 6/30\n",
            "254/254 [==============================] - 8s 32ms/step - loss: 0.1670 - accuracy: 0.9380 - val_loss: 0.2202 - val_accuracy: 0.9231\n",
            "Epoch 7/30\n",
            "254/254 [==============================] - 7s 27ms/step - loss: 0.1709 - accuracy: 0.9368 - val_loss: 0.2019 - val_accuracy: 0.9329\n",
            "Epoch 8/30\n",
            "254/254 [==============================] - 8s 31ms/step - loss: 0.1594 - accuracy: 0.9411 - val_loss: 0.1888 - val_accuracy: 0.9310\n",
            "Epoch 9/30\n",
            "254/254 [==============================] - 7s 28ms/step - loss: 0.1595 - accuracy: 0.9428 - val_loss: 0.1754 - val_accuracy: 0.9359\n",
            "Epoch 10/30\n",
            "254/254 [==============================] - 8s 30ms/step - loss: 0.1496 - accuracy: 0.9464 - val_loss: 0.1896 - val_accuracy: 0.9305\n",
            "Epoch 11/30\n",
            "254/254 [==============================] - 8s 30ms/step - loss: 0.1593 - accuracy: 0.9430 - val_loss: 0.1808 - val_accuracy: 0.9389\n",
            "Epoch 12/30\n",
            "254/254 [==============================] - 7s 28ms/step - loss: 0.1502 - accuracy: 0.9454 - val_loss: 0.1867 - val_accuracy: 0.9398\n",
            "Epoch 13/30\n",
            "254/254 [==============================] - 8s 31ms/step - loss: 0.1543 - accuracy: 0.9428 - val_loss: 0.1831 - val_accuracy: 0.9349\n",
            "Epoch 14/30\n",
            "254/254 [==============================] - 6s 25ms/step - loss: 0.1494 - accuracy: 0.9444 - val_loss: 0.1710 - val_accuracy: 0.9418\n",
            "Epoch 15/30\n",
            "254/254 [==============================] - 9s 34ms/step - loss: 0.1405 - accuracy: 0.9503 - val_loss: 0.1827 - val_accuracy: 0.9364\n",
            "Epoch 16/30\n",
            "254/254 [==============================] - 7s 26ms/step - loss: 0.1372 - accuracy: 0.9504 - val_loss: 0.1776 - val_accuracy: 0.9403\n",
            "Epoch 17/30\n",
            "254/254 [==============================] - 9s 35ms/step - loss: 0.1371 - accuracy: 0.9501 - val_loss: 0.1800 - val_accuracy: 0.9398\n",
            "Epoch 18/30\n",
            "254/254 [==============================] - 6s 25ms/step - loss: 0.1462 - accuracy: 0.9472 - val_loss: 0.1805 - val_accuracy: 0.9393\n",
            "Epoch 19/30\n",
            "254/254 [==============================] - 9s 34ms/step - loss: 0.1380 - accuracy: 0.9523 - val_loss: 0.1655 - val_accuracy: 0.9453\n",
            "Epoch 20/30\n",
            "254/254 [==============================] - 6s 25ms/step - loss: 0.1401 - accuracy: 0.9503 - val_loss: 0.1669 - val_accuracy: 0.9389\n",
            "Epoch 21/30\n",
            "254/254 [==============================] - 9s 34ms/step - loss: 0.1219 - accuracy: 0.9562 - val_loss: 0.1515 - val_accuracy: 0.9497\n",
            "Epoch 22/30\n",
            "254/254 [==============================] - 7s 26ms/step - loss: 0.1292 - accuracy: 0.9527 - val_loss: 0.1819 - val_accuracy: 0.9364\n",
            "Epoch 23/30\n",
            "254/254 [==============================] - 8s 33ms/step - loss: 0.1338 - accuracy: 0.9524 - val_loss: 0.1563 - val_accuracy: 0.9453\n",
            "Epoch 24/30\n",
            "254/254 [==============================] - 7s 27ms/step - loss: 0.1305 - accuracy: 0.9527 - val_loss: 0.1692 - val_accuracy: 0.9413\n",
            "Epoch 25/30\n",
            "254/254 [==============================] - 8s 32ms/step - loss: 0.1237 - accuracy: 0.9555 - val_loss: 0.1666 - val_accuracy: 0.9467\n",
            "Epoch 26/30\n",
            "254/254 [==============================] - 7s 27ms/step - loss: 0.1294 - accuracy: 0.9530 - val_loss: 0.1750 - val_accuracy: 0.9433\n",
            "Epoch 27/30\n",
            "254/254 [==============================] - 8s 31ms/step - loss: 0.1222 - accuracy: 0.9545 - val_loss: 0.1885 - val_accuracy: 0.9349\n",
            "Epoch 28/30\n",
            "254/254 [==============================] - 7s 29ms/step - loss: 0.1205 - accuracy: 0.9556 - val_loss: 0.1765 - val_accuracy: 0.9393\n",
            "Epoch 29/30\n",
            "254/254 [==============================] - 7s 26ms/step - loss: 0.1154 - accuracy: 0.9594 - val_loss: 0.1818 - val_accuracy: 0.9418\n",
            "Epoch 30/30\n",
            "254/254 [==============================] - 8s 33ms/step - loss: 0.1302 - accuracy: 0.9536 - val_loss: 0.1647 - val_accuracy: 0.9482\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x78cb77d110f0>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "model.fit(X_train, y_train, epochs=30, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.models.load_model('/content/my-lstm.h5')\n",
        "data, lab = process_audio_file('door_open','62d61e14449ba87643e73792.wav')\n",
        "data = pad2d(data,40)\n",
        "out=model.predict(tf.expand_dims(data, axis=0) )\n",
        "percentage_list = []\n",
        "for i in range(len(out[0])):\n",
        "    percentage_list.append(\"{0:.2%}\".format(out[0][i]))\n",
        "classes=['door_open','door_close','door_stop']\n",
        "my_result = list(zip(classes, percentage_list))\n",
        "for i in range(len(my_result)):\n",
        "    print(my_result[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39WOJQF0lCiV",
        "outputId": "8e1e5628-4f7c-4bfb-f3cf-63662b53dec6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22050\n",
            "(22050,)\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "('door_open', '100.00%')\n",
            "('door_close', '0.00%')\n",
            "('door_stop', '0.00%')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"my-lstm.h5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kf5c30bYbSsH",
        "outputId": "45ccf67f-bc2d-4aa3-cbf8-7ae5819d43b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import lite\n",
        "model=tf.keras.models.load_model('/content/my-lstm.h5')\n",
        "converter = lite.TFLiteConverter.from_keras_model( model ) # Your model's name\n",
        "converter.target_spec.supported_ops = [\n",
        "  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\n",
        "  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\n",
        "]\n",
        "model = converter.convert()\n",
        "file = open( 'my-lstm.tflite' , 'wb' )\n",
        "file.write( model )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crOpyFs3dJtM",
        "outputId": "cc667e02-718d-4334-d905-195af5b5cd19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "176624"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter = tf.lite.Interpreter(model_path=\"/content/my-lstm.tflite\")\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n"
      ],
      "metadata": {
        "id": "G8o2EqAOySgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter.allocate_tensors()\n",
        "\n",
        "print(input_details)\n",
        "# output details\n",
        "print(output_details)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkbstsbE1p_R",
        "outputId": "dde8f4cf-db9e-40df-cdfe-c974b56f2bf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'name': 'serving_default_input_7:0', 'index': 0, 'shape': array([ 1, 20, 40], dtype=int32), 'shape_signature': array([-1, 20, 40], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n",
            "[{'name': 'StatefulPartitionedCall:0', 'index': 58, 'shape': array([1, 3], dtype=int32), 'shape_signature': array([-1,  3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data, lab = process_audio_file('door_close','62d71c08449ba86a10f47158.wav')\n",
        "data = pad2d(data,40)\n",
        "interpreter.set_tensor(input_details[0]['index'], [data])"
      ],
      "metadata": {
        "id": "Fv55u0Yp205L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interpreter.invoke()"
      ],
      "metadata": {
        "id": "7Nzhd7sI3V2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " # output_details[0]['index'] = the index which provides the input\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "output_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRTclNt93Nzi",
        "outputId": "9eb0a4cc-1701-453f-fe78-e0f644b66f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.8604941e-03, 9.9537969e-01, 7.5987558e-04]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}